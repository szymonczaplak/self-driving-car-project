{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Szymon\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Szymon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Szymon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Szymon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Szymon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Szymon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Szymon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import keras \n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398.0</td>\n",
       "      <td>101.857902</td>\n",
       "      <td>60.925663</td>\n",
       "      <td>474.156302</td>\n",
       "      <td>231.819254</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.0</td>\n",
       "      <td>101.542193</td>\n",
       "      <td>60.925663</td>\n",
       "      <td>472.084688</td>\n",
       "      <td>231.819254</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394.0</td>\n",
       "      <td>101.542193</td>\n",
       "      <td>60.925663</td>\n",
       "      <td>470.015662</td>\n",
       "      <td>231.819254</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>392.0</td>\n",
       "      <td>101.542193</td>\n",
       "      <td>60.925663</td>\n",
       "      <td>467.944048</td>\n",
       "      <td>231.819254</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>390.0</td>\n",
       "      <td>101.542193</td>\n",
       "      <td>60.925663</td>\n",
       "      <td>465.875022</td>\n",
       "      <td>231.819254</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_1    sensor_2   sensor_3    sensor_4    sensor_5  decision\n",
       "0     398.0  101.857902  60.925663  474.156302  231.819254  straight\n",
       "1     396.0  101.542193  60.925663  472.084688  231.819254  straight\n",
       "2     394.0  101.542193  60.925663  470.015662  231.819254  straight\n",
       "3     392.0  101.542193  60.925663  467.944048  231.819254  straight\n",
       "4     390.0  101.542193  60.925663  465.875022  231.819254  straight"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'decision']\n",
    "data = pd.read_csv('output2.csv', names=headers)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data, columns=['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8002 entries, 0 to 8001\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sensor_1           8002 non-null   float64\n",
      " 1   sensor_2           8002 non-null   float64\n",
      " 2   sensor_3           8002 non-null   float64\n",
      " 3   sensor_4           8002 non-null   float64\n",
      " 4   sensor_5           8002 non-null   float64\n",
      " 5   decision_left      8002 non-null   uint8  \n",
      " 6   decision_right     8002 non-null   uint8  \n",
      " 7   decision_straight  8002 non-null   uint8  \n",
      "dtypes: float64(5), uint8(3)\n",
      "memory usage: 336.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[list(df.columns)[:5]]\n",
    "y = df[list(df.columns)[5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, shuffle=True, test_size=0.33, random_state=42, stratify=data['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.clip(X_train, -5, 5)\n",
    "X_test = np.clip(X_test, -5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={0: 1 - sum([el[0] for el in y_train]) / len(y_train), # left\n",
    "               1: 1 - sum([el[1] for el in y_train]) / len(y_train), # right\n",
    "               2: 1 - sum([el[2] for el in y_train]) / len(y_train), # straight\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7338183174780825, 1: 0.9350867375489648, 2: 0.3310949449729528}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    network = keras.Sequential()\n",
    "    network.add(Dense(4000, activation='relu', input_shape=(5,)))\n",
    "    network.add(Dense(3, activation='softmax'))\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "def build_model_2():\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(5,1))\n",
    "    #First Conv1D layer\n",
    "    conv = Conv1D(45,3, padding='valid', activation='relu', strides=1)(inputs)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    \n",
    "    #Flatten layer\n",
    "    conv = Flatten()(conv)\n",
    "\n",
    "    #Dense Layer 1\n",
    "    conv = Dense(4500, activation='relu')(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    outputs = Dense(3, activation='softmax')(conv)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(model_f, train_data, train_targets, epochs, class_weights):\n",
    "    k = 5\n",
    "    num_val_samples = len(train_data) // k\n",
    "    num_epochs = epochs\n",
    "    all_scores = []\n",
    "    for i in range(k):\n",
    "        print('processing fold #', i)\n",
    "        # Prepare the validation data: data from partition # k\n",
    "        val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        # Prepare the training data: data from all other partitions\n",
    "        partial_train_data = np.concatenate(\n",
    "            [train_data[:i * num_val_samples],\n",
    "             train_data[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [train_targets[:i * num_val_samples],\n",
    "             train_targets[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "\n",
    "        # Build the Keras model (already compiled)\n",
    "        model = model_f()\n",
    "        # Train the model (in silent mode, verbose=0)\n",
    "        model.fit(partial_train_data, partial_train_targets,\n",
    "                  epochs=num_epochs, batch_size=124, verbose=1, class_weight=class_weights)\n",
    "        # Evaluate the model on the validation data\n",
    "        val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
    "        all_scores.append(val_mae)\n",
    "    return mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/45\n",
      "4289/4289 [==============================] - 0s 77us/step - loss: 0.3784 - accuracy: 0.7554\n",
      "Epoch 2/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3548 - accuracy: 0.7696\n",
      "Epoch 3/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3440 - accuracy: 0.7668\n",
      "Epoch 4/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3396 - accuracy: 0.7603\n",
      "Epoch 5/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3332 - accuracy: 0.7550\n",
      "Epoch 6/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3298 - accuracy: 0.7603\n",
      "Epoch 7/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3289 - accuracy: 0.7470\n",
      "Epoch 8/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3257 - accuracy: 0.7585\n",
      "Epoch 9/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3227 - accuracy: 0.7568\n",
      "Epoch 10/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3238 - accuracy: 0.7501\n",
      "Epoch 11/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3198 - accuracy: 0.7608\n",
      "Epoch 12/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3194 - accuracy: 0.7582\n",
      "Epoch 13/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3181 - accuracy: 0.7612\n",
      "Epoch 14/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3179 - accuracy: 0.7578\n",
      "Epoch 15/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3167 - accuracy: 0.7610\n",
      "Epoch 16/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3147 - accuracy: 0.7533\n",
      "Epoch 17/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3134 - accuracy: 0.7612\n",
      "Epoch 18/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3136 - accuracy: 0.7612\n",
      "Epoch 19/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3130 - accuracy: 0.7631\n",
      "Epoch 20/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3110 - accuracy: 0.7617\n",
      "Epoch 21/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3110 - accuracy: 0.7561\n",
      "Epoch 22/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3113 - accuracy: 0.7582\n",
      "Epoch 23/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3087 - accuracy: 0.7638\n",
      "Epoch 24/45\n",
      "4289/4289 [==============================] - 0s 25us/step - loss: 0.3097 - accuracy: 0.7610\n",
      "Epoch 25/45\n",
      "4289/4289 [==============================] - 0s 25us/step - loss: 0.3104 - accuracy: 0.7640\n",
      "Epoch 26/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3090 - accuracy: 0.7645\n",
      "Epoch 27/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3081 - accuracy: 0.7568\n",
      "Epoch 28/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3073 - accuracy: 0.7599\n",
      "Epoch 29/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3062 - accuracy: 0.7626\n",
      "Epoch 30/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3073 - accuracy: 0.7640\n",
      "Epoch 31/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3077 - accuracy: 0.7610\n",
      "Epoch 32/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3048 - accuracy: 0.7631\n",
      "Epoch 33/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3039 - accuracy: 0.7592\n",
      "Epoch 34/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3073 - accuracy: 0.7622\n",
      "Epoch 35/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3042 - accuracy: 0.7682\n",
      "Epoch 36/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3041 - accuracy: 0.7587\n",
      "Epoch 37/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3015 - accuracy: 0.7631\n",
      "Epoch 38/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3053 - accuracy: 0.7643\n",
      "Epoch 39/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3030 - accuracy: 0.7631\n",
      "Epoch 40/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3003 - accuracy: 0.7654\n",
      "Epoch 41/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3035 - accuracy: 0.7631\n",
      "Epoch 42/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3004 - accuracy: 0.7713\n",
      "Epoch 43/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3023 - accuracy: 0.7654\n",
      "Epoch 44/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3018 - accuracy: 0.7624\n",
      "Epoch 45/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3011 - accuracy: 0.7631\n",
      "1072/1072 [==============================] - 0s 134us/step\n",
      "processing fold # 1\n",
      "Epoch 1/45\n",
      "4289/4289 [==============================] - 0s 62us/step - loss: 0.3795 - accuracy: 0.7561\n",
      "Epoch 2/45\n",
      "4289/4289 [==============================] - 0s 27us/step - loss: 0.3540 - accuracy: 0.7675\n",
      "Epoch 3/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3445 - accuracy: 0.7654\n",
      "Epoch 4/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3364 - accuracy: 0.7540\n",
      "Epoch 5/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3353 - accuracy: 0.7477\n",
      "Epoch 6/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3297 - accuracy: 0.7496\n",
      "Epoch 7/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3281 - accuracy: 0.7466\n",
      "Epoch 8/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3251 - accuracy: 0.7459\n",
      "Epoch 9/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3233 - accuracy: 0.7557 0s - loss: 0.3264 - accuracy: 0.75\n",
      "Epoch 10/45\n",
      "4289/4289 [==============================] - 0s 28us/step - loss: 0.3223 - accuracy: 0.7550\n",
      "Epoch 11/45\n",
      "4289/4289 [==============================] - 0s 29us/step - loss: 0.3186 - accuracy: 0.7559\n",
      "Epoch 12/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3172 - accuracy: 0.7568\n",
      "Epoch 13/45\n",
      "4289/4289 [==============================] - 0s 26us/step - loss: 0.3174 - accuracy: 0.7512\n",
      "Epoch 14/45\n",
      "4289/4289 [==============================] - 0s 27us/step - loss: 0.3154 - accuracy: 0.7606\n",
      "Epoch 15/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3156 - accuracy: 0.7494\n",
      "Epoch 16/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3119 - accuracy: 0.7571\n",
      "Epoch 17/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3145 - accuracy: 0.7587\n",
      "Epoch 18/45\n",
      "4289/4289 [==============================] - 0s 25us/step - loss: 0.3117 - accuracy: 0.7529\n",
      "Epoch 19/45\n",
      "4289/4289 [==============================] - 0s 27us/step - loss: 0.3123 - accuracy: 0.7571\n",
      "Epoch 20/45\n",
      "4289/4289 [==============================] - 0s 25us/step - loss: 0.3107 - accuracy: 0.7564\n",
      "Epoch 21/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3087 - accuracy: 0.7561\n",
      "Epoch 22/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3085 - accuracy: 0.7589\n",
      "Epoch 23/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3089 - accuracy: 0.7585\n",
      "Epoch 24/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3076 - accuracy: 0.7589\n",
      "Epoch 25/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3075 - accuracy: 0.7592\n",
      "Epoch 26/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3088 - accuracy: 0.7524\n",
      "Epoch 27/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3066 - accuracy: 0.7540\n",
      "Epoch 28/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3072 - accuracy: 0.7543\n",
      "Epoch 29/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3066 - accuracy: 0.7564\n",
      "Epoch 30/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3035 - accuracy: 0.7596\n",
      "Epoch 31/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3076 - accuracy: 0.7571\n",
      "Epoch 32/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3039 - accuracy: 0.7603\n",
      "Epoch 33/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3036 - accuracy: 0.7589\n",
      "Epoch 34/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3042 - accuracy: 0.7633\n",
      "Epoch 35/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3033 - accuracy: 0.7626\n",
      "Epoch 36/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3032 - accuracy: 0.7599\n",
      "Epoch 37/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3013 - accuracy: 0.7636\n",
      "Epoch 38/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3045 - accuracy: 0.7629\n",
      "Epoch 39/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3012 - accuracy: 0.7640\n",
      "Epoch 40/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3025 - accuracy: 0.7505\n",
      "Epoch 41/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.2998 - accuracy: 0.7592\n",
      "Epoch 42/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3005 - accuracy: 0.7657\n",
      "Epoch 43/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3014 - accuracy: 0.7640\n",
      "Epoch 44/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3001 - accuracy: 0.7529\n",
      "Epoch 45/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3009 - accuracy: 0.7564\n",
      "1072/1072 [==============================] - 0s 119us/step\n",
      "processing fold # 2\n",
      "Epoch 1/45\n",
      "4289/4289 [==============================] - 0s 60us/step - loss: 0.3831 - accuracy: 0.7622\n",
      "Epoch 2/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3557 - accuracy: 0.7638\n",
      "Epoch 3/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3454 - accuracy: 0.7687\n",
      "Epoch 4/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3412 - accuracy: 0.7603\n",
      "Epoch 5/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3359 - accuracy: 0.7545\n",
      "Epoch 6/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3320 - accuracy: 0.7601\n",
      "Epoch 7/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3286 - accuracy: 0.7547\n",
      "Epoch 8/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3293 - accuracy: 0.7526\n",
      "Epoch 9/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3258 - accuracy: 0.7561\n",
      "Epoch 10/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3240 - accuracy: 0.7594\n",
      "Epoch 11/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3248 - accuracy: 0.7561\n",
      "Epoch 12/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3216 - accuracy: 0.7538\n",
      "Epoch 13/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3208 - accuracy: 0.7552\n",
      "Epoch 14/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3183 - accuracy: 0.7636\n",
      "Epoch 15/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3162 - accuracy: 0.7477\n",
      "Epoch 16/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3181 - accuracy: 0.7524\n",
      "Epoch 17/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3164 - accuracy: 0.7582\n",
      "Epoch 18/45\n",
      "4289/4289 [==============================] - 0s 25us/step - loss: 0.3170 - accuracy: 0.7564\n",
      "Epoch 19/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3142 - accuracy: 0.7578\n",
      "Epoch 20/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3140 - accuracy: 0.7589\n",
      "Epoch 21/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3130 - accuracy: 0.7561\n",
      "Epoch 22/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3165 - accuracy: 0.7589\n",
      "Epoch 23/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3132 - accuracy: 0.7575\n",
      "Epoch 24/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3118 - accuracy: 0.7568\n",
      "Epoch 25/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3103 - accuracy: 0.7589\n",
      "Epoch 26/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3084 - accuracy: 0.7668\n",
      "Epoch 27/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3107 - accuracy: 0.7564\n",
      "Epoch 28/45\n",
      "4289/4289 [==============================] - 0s 20us/step - loss: 0.3093 - accuracy: 0.7631\n",
      "Epoch 29/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3087 - accuracy: 0.7640\n",
      "Epoch 30/45\n",
      "4289/4289 [==============================] - 0s 24us/step - loss: 0.3081 - accuracy: 0.7629\n",
      "Epoch 31/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3079 - accuracy: 0.7622\n",
      "Epoch 32/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3085 - accuracy: 0.7571\n",
      "Epoch 33/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3057 - accuracy: 0.7666\n",
      "Epoch 34/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3093 - accuracy: 0.7554\n",
      "Epoch 35/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3074 - accuracy: 0.7619\n",
      "Epoch 36/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3068 - accuracy: 0.7610\n",
      "Epoch 37/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3077 - accuracy: 0.7585\n",
      "Epoch 38/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3051 - accuracy: 0.7619\n",
      "Epoch 39/45\n",
      "4289/4289 [==============================] - 0s 23us/step - loss: 0.3031 - accuracy: 0.7675\n",
      "Epoch 40/45\n",
      "4289/4289 [==============================] - 0s 21us/step - loss: 0.3058 - accuracy: 0.7622\n",
      "Epoch 41/45\n",
      "4289/4289 [==============================] - 0s 22us/step - loss: 0.3041 - accuracy: 0.7659\n",
      "Epoch 42/45\n",
      "2604/4289 [=================>............] - ETA: 0s - loss: 0.2997 - accuracy: 0.7746"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-224-005039c92fa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-222-0a90617e120b>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[1;34m(model_f, train_data, train_targets, epochs, class_weights)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Train the model (in silent mode, verbose=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         model.fit(partial_train_data, partial_train_targets,\n\u001b[1;32m---> 26\u001b[1;33m                   epochs=num_epochs, batch_size=124, verbose=1, class_weight=class_weights)\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Evaluate the model on the validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mval_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_classifier(build_model, X_train, y_train, 45, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5361 samples, validate on 2641 samples\n",
      "Epoch 1/40\n",
      "5361/5361 [==============================] - 1s 143us/step - loss: 0.6086 - accuracy: 0.7752 - val_loss: 0.5664 - val_accuracy: 0.7823\n",
      "Epoch 2/40\n",
      "5361/5361 [==============================] - 1s 95us/step - loss: 0.5705 - accuracy: 0.7782 - val_loss: 0.5426 - val_accuracy: 0.7861\n",
      "Epoch 3/40\n",
      "5361/5361 [==============================] - 0s 92us/step - loss: 0.5575 - accuracy: 0.7840 - val_loss: 0.5380 - val_accuracy: 0.7876\n",
      "Epoch 4/40\n",
      "5361/5361 [==============================] - 1s 101us/step - loss: 0.5507 - accuracy: 0.7819 - val_loss: 0.5377 - val_accuracy: 0.7827\n",
      "Epoch 5/40\n",
      "5361/5361 [==============================] - 1s 108us/step - loss: 0.5472 - accuracy: 0.7791 - val_loss: 0.5358 - val_accuracy: 0.7872\n",
      "Epoch 6/40\n",
      "5361/5361 [==============================] - 1s 106us/step - loss: 0.5436 - accuracy: 0.7840 - val_loss: 0.5282 - val_accuracy: 0.7827\n",
      "Epoch 7/40\n",
      "5361/5361 [==============================] - 1s 100us/step - loss: 0.5422 - accuracy: 0.7842 - val_loss: 0.5270 - val_accuracy: 0.7853\n",
      "Epoch 8/40\n",
      "5361/5361 [==============================] - 1s 99us/step - loss: 0.5389 - accuracy: 0.7862 - val_loss: 0.5221 - val_accuracy: 0.7876\n",
      "Epoch 9/40\n",
      "5361/5361 [==============================] - 1s 100us/step - loss: 0.5373 - accuracy: 0.7851 - val_loss: 0.5295 - val_accuracy: 0.7876\n",
      "Epoch 10/40\n",
      "5361/5361 [==============================] - 1s 95us/step - loss: 0.5367 - accuracy: 0.7851 - val_loss: 0.5182 - val_accuracy: 0.7849\n",
      "Epoch 11/40\n",
      "5361/5361 [==============================] - 1s 107us/step - loss: 0.5352 - accuracy: 0.7881 - val_loss: 0.5400 - val_accuracy: 0.7766\n",
      "Epoch 12/40\n",
      "5361/5361 [==============================] - 1s 103us/step - loss: 0.5354 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7868\n",
      "Epoch 13/40\n",
      "5361/5361 [==============================] - 1s 101us/step - loss: 0.5335 - accuracy: 0.7859 - val_loss: 0.5202 - val_accuracy: 0.7872\n",
      "Epoch 14/40\n",
      "5361/5361 [==============================] - 1s 106us/step - loss: 0.5339 - accuracy: 0.7842 - val_loss: 0.5291 - val_accuracy: 0.7891\n",
      "Epoch 15/40\n",
      "5361/5361 [==============================] - 1s 113us/step - loss: 0.5318 - accuracy: 0.7855 - val_loss: 0.5250 - val_accuracy: 0.7830\n",
      "Epoch 16/40\n",
      "5361/5361 [==============================] - 1s 102us/step - loss: 0.5301 - accuracy: 0.7844 - val_loss: 0.5306 - val_accuracy: 0.7899\n",
      "Epoch 17/40\n",
      "5361/5361 [==============================] - 1s 102us/step - loss: 0.5294 - accuracy: 0.7874 - val_loss: 0.5114 - val_accuracy: 0.7864\n",
      "Epoch 18/40\n",
      "5361/5361 [==============================] - 1s 101us/step - loss: 0.5286 - accuracy: 0.7872 - val_loss: 0.5267 - val_accuracy: 0.7925\n",
      "Epoch 19/40\n",
      "5361/5361 [==============================] - 1s 95us/step - loss: 0.5282 - accuracy: 0.7898 - val_loss: 0.5624 - val_accuracy: 0.7793\n",
      "Epoch 20/40\n",
      "5361/5361 [==============================] - 1s 97us/step - loss: 0.5290 - accuracy: 0.7898 - val_loss: 0.5230 - val_accuracy: 0.7921\n",
      "Epoch 21/40\n",
      "5361/5361 [==============================] - 1s 95us/step - loss: 0.5266 - accuracy: 0.7905 - val_loss: 0.5058 - val_accuracy: 0.7910\n",
      "Epoch 22/40\n",
      "5361/5361 [==============================] - 1s 98us/step - loss: 0.5272 - accuracy: 0.7874 - val_loss: 0.5218 - val_accuracy: 0.7834\n",
      "Epoch 23/40\n",
      "5361/5361 [==============================] - 1s 94us/step - loss: 0.5239 - accuracy: 0.7909 - val_loss: 0.5150 - val_accuracy: 0.7914\n",
      "Epoch 24/40\n",
      "5361/5361 [==============================] - 1s 109us/step - loss: 0.5222 - accuracy: 0.7922 - val_loss: 0.5312 - val_accuracy: 0.7883\n",
      "Epoch 25/40\n",
      "5361/5361 [==============================] - 1s 105us/step - loss: 0.5252 - accuracy: 0.7877 - val_loss: 0.5148 - val_accuracy: 0.7917\n",
      "Epoch 26/40\n",
      "5361/5361 [==============================] - 1s 105us/step - loss: 0.5228 - accuracy: 0.7909 - val_loss: 0.5123 - val_accuracy: 0.7880\n",
      "Epoch 27/40\n",
      "5361/5361 [==============================] - 1s 108us/step - loss: 0.5206 - accuracy: 0.7883 - val_loss: 0.5350 - val_accuracy: 0.7872\n",
      "Epoch 28/40\n",
      "5361/5361 [==============================] - 1s 96us/step - loss: 0.5194 - accuracy: 0.7875 - val_loss: 0.5287 - val_accuracy: 0.7891\n",
      "Epoch 29/40\n",
      "5361/5361 [==============================] - 1s 104us/step - loss: 0.5207 - accuracy: 0.7913 - val_loss: 0.5321 - val_accuracy: 0.7880\n",
      "Epoch 30/40\n",
      "5361/5361 [==============================] - 1s 99us/step - loss: 0.5236 - accuracy: 0.7875 - val_loss: 0.5189 - val_accuracy: 0.7857\n",
      "Epoch 31/40\n",
      "5361/5361 [==============================] - 1s 101us/step - loss: 0.5204 - accuracy: 0.7874 - val_loss: 0.5072 - val_accuracy: 0.7940\n",
      "Epoch 32/40\n",
      "5361/5361 [==============================] - 1s 105us/step - loss: 0.5197 - accuracy: 0.7913 - val_loss: 0.5238 - val_accuracy: 0.7929\n",
      "Epoch 33/40\n",
      "5361/5361 [==============================] - 1s 95us/step - loss: 0.5216 - accuracy: 0.7905 - val_loss: 0.5251 - val_accuracy: 0.7883\n",
      "Epoch 34/40\n",
      "5361/5361 [==============================] - 1s 96us/step - loss: 0.5188 - accuracy: 0.7902 - val_loss: 0.5279 - val_accuracy: 0.7793\n",
      "Epoch 35/40\n",
      "5361/5361 [==============================] - 1s 105us/step - loss: 0.5185 - accuracy: 0.7885 - val_loss: 0.5342 - val_accuracy: 0.7830\n",
      "Epoch 36/40\n",
      "5361/5361 [==============================] - 0s 93us/step - loss: 0.5179 - accuracy: 0.7909 - val_loss: 0.5231 - val_accuracy: 0.7914\n",
      "Epoch 37/40\n",
      "5361/5361 [==============================] - 1s 99us/step - loss: 0.5182 - accuracy: 0.7924 - val_loss: 0.5255 - val_accuracy: 0.7883\n",
      "Epoch 38/40\n",
      "5361/5361 [==============================] - 1s 112us/step - loss: 0.5173 - accuracy: 0.7931 - val_loss: 0.5100 - val_accuracy: 0.7914\n",
      "Epoch 39/40\n",
      "5361/5361 [==============================] - 1s 94us/step - loss: 0.5171 - accuracy: 0.7902 - val_loss: 0.5066 - val_accuracy: 0.7910\n",
      "Epoch 40/40\n",
      "5361/5361 [==============================] - 0s 93us/step - loss: 0.5145 - accuracy: 0.7941 - val_loss: 0.5257 - val_accuracy: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2ee56eff748>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 335    5  363]\n",
      " [  30   35  106]\n",
      " [  47    1 1719]]\n"
     ]
    }
   ],
   "source": [
    "pred_labels = [np.argmax(el) for el in predictions]\n",
    "true_labels = [np.argmax(el) for el in y_test]\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(\"Confusion matrix:\\n{}\".\\\n",
    "      format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_model_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
